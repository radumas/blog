---
layout: post
section-type: post
title: "OPS CodeDay: Dash Plotly Map + Graph"
published: true
date: 2017-08-10 15:00:00 -0500
categories: ['tutorial']
author: Raphael Dumas
summary: "I try to make a demo interactive web map linked to a graph using plotly and the python web server Dash."
tags: [ 'dash','plotly', 'python','visualization']
thumbnail: map  
---

*On August 10th, 2017, the Ontario Public Service hosted a Code Day, where public servants across ministries and levels of government hacked on work projects in little clusters, helping each other out and learning in the process.* 

My goal was to explore the dashboarding potential of [plotly's dash ](https://plot.ly/products/dash/), a web-server framework combining Flask and plotly's python library. I wanted to learn more about plotly and dash while exploring the potential for linking an interactive map with graphs, in this case 24-hr timeseries graph of the average travel times on the selected segment based on the City's Bluetooth sensors (from the [Open Data](https://www1.toronto.ca/wps/portal/contentonly?vgnextoid=0b3abcfaf9c6a510VgnVCM10000071d60f89RCRD&vgnextchannel=1a66e03bb8d1e310VgnVCM10000071d60f89RCRD) ). This post details what I accomplished during the day. It's derived from a Jupyter Notebook which you can see in its full interactive glory [here]({{site.parenturl}}codeday_dash/map_development.html) and the actual Notebook on [Github here](https://github.com/radumas/codeday_dash/blob/master/map%20development.ipynb). **Note, none of the interactive plots are in this post at the moment...** (*but they will be in iframes soon*)


## 24-hr Plot

```python
from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
import plotly.graph_objs as go
init_notebook_mode(connected=True)
```

I downloaded the 2017 data and the WGS84 shapefile for the routes. Since I'm remote I'm going to reimport the data into a PostgreSQL database on my local computer. After unzipping the shapefile, I imported it into the database using the following command in bash:

```bash
shp2pgsql -S -s 4326 -D bluetooth_routes_wgs84.shp bluetooth.routes | psql -d bigdata
```

The sql we used to create the data exports can be found on the City of Toronto's [Github](https://github.com/CityofToronto/bdit_data-sources/blob/master/bluetooth/aggr_5min_opendata_export.sql). Note that, in order to make the exported data match *as close as possible* the data from the live feed, a little switcheroo was performed:
```sql
REPLACE(to_char( (datetime_bin AT TIME ZONE 'America/Toronto' + interval '5 minutes'), 'YYYY-MM-DD HH24:MI:SSOF'), ' ', 'T')
```
So this will have to be switched back in order to import that data into the database.


```python
from psycopg2 import connect
import psycopg2.sql as pgsql
con = connect(database='bigdata')
```


```python
import pandas
import pandas.io.sql as pandasql
import sqlalchemy
```


```python
bt_2017 = pandas.read_csv('bt_2017.csv')
bt_2017
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>resultId</th>
      <th>timeInSeconds</th>
      <th>count</th>
      <th>updated</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>J_I</td>
      <td>56</td>
      <td>16</td>
      <td>2017-01-01T00:05:00-05</td>
    </tr>
    <tr>
      <th>1</th>
      <td>J_I</td>
      <td>60</td>
      <td>9</td>
      <td>2017-01-01T00:10:00-05</td>
    </tr>
    <tr>
      <th>2</th>
      <td>J_I</td>
      <td>60</td>
      <td>8</td>
      <td>2017-01-01T00:15:00-05</td>
    </tr>
    <tr>
      <th>3</th>
      <td>J_I</td>
      <td>60</td>
      <td>8</td>
      <td>2017-01-01T00:20:00-05</td>
    </tr>
    <tr>
      <th>4</th>
      <td>J_I</td>
      <td>55</td>
      <td>17</td>
      <td>2017-01-01T00:25:00-05</td>
    </tr>
    <tr>
      <th>5</th>
      <td>J_I</td>
      <td>53</td>
      <td>15</td>
      <td>2017-01-01T00:30:00-05</td>
    </tr>
    <tr>
      <th>6</th>
      <td>J_I</td>
      <td>58</td>
      <td>13</td>
      <td>2017-01-01T00:35:00-05</td>
    </tr>
    <tr>
      <th>7</th>
      <td>J_I</td>
      <td>55</td>
      <td>18</td>
      <td>2017-01-01T00:40:00-05</td>
    </tr>
    <tr>
      <th>8</th>
      <td>J_I</td>
      <td>58</td>
      <td>22</td>
      <td>2017-01-01T00:45:00-05</td>
    </tr>
    <tr>
      <th>9</th>
      <td>J_I</td>
      <td>54</td>
      <td>19</td>
      <td>2017-01-01T00:50:00-05</td>
    </tr>
    <tr>
      <th>10</th>
      <td>J_I</td>
      <td>59</td>
      <td>19</td>
      <td>2017-01-01T00:55:00-05</td>
    </tr>
    <tr>
      <th>11</th>
      <td>J_I</td>
      <td>57</td>
      <td>11</td>
      <td>2017-01-01T01:00:00-05</td>
    </tr>
    <tr>
      <th>12</th>
      <td>J_I</td>
      <td>54</td>
      <td>11</td>
      <td>2017-01-01T01:05:00-05</td>
    </tr>
    <tr>
      <th>13</th>
      <td>J_I</td>
      <td>59</td>
      <td>15</td>
      <td>2017-01-01T01:10:00-05</td>
    </tr>
    <tr>
      <th>14</th>
      <td>J_I</td>
      <td>54</td>
      <td>12</td>
      <td>2017-01-01T01:15:00-05</td>
    </tr>
    <tr>
      <th>15</th>
      <td>J_I</td>
      <td>57</td>
      <td>23</td>
      <td>2017-01-01T01:20:00-05</td>
    </tr>
    <tr>
      <th>16</th>
      <td>J_I</td>
      <td>58</td>
      <td>11</td>
      <td>2017-01-01T01:25:00-05</td>
    </tr>
    <tr>
      <th>17</th>
      <td>J_I</td>
      <td>51</td>
      <td>15</td>
      <td>2017-01-01T01:30:00-05</td>
    </tr>
    <tr>
      <th>18</th>
      <td>J_I</td>
      <td>55</td>
      <td>17</td>
      <td>2017-01-01T01:35:00-05</td>
    </tr>
    <tr>
      <th>19</th>
      <td>J_I</td>
      <td>53</td>
      <td>8</td>
      <td>2017-01-01T01:40:00-05</td>
    </tr>
    <tr>
      <th>20</th>
      <td>J_I</td>
      <td>58</td>
      <td>23</td>
      <td>2017-01-01T01:45:00-05</td>
    </tr>
    <tr>
      <th>21</th>
      <td>J_I</td>
      <td>52</td>
      <td>21</td>
      <td>2017-01-01T01:50:00-05</td>
    </tr>
    <tr>
      <th>22</th>
      <td>J_I</td>
      <td>60</td>
      <td>10</td>
      <td>2017-01-01T01:55:00-05</td>
    </tr>
    <tr>
      <th>23</th>
      <td>J_I</td>
      <td>57</td>
      <td>10</td>
      <td>2017-01-01T02:00:00-05</td>
    </tr>
    <tr>
      <th>24</th>
      <td>J_I</td>
      <td>49</td>
      <td>11</td>
      <td>2017-01-01T02:05:00-05</td>
    </tr>
    <tr>
      <th>25</th>
      <td>J_I</td>
      <td>55</td>
      <td>13</td>
      <td>2017-01-01T02:10:00-05</td>
    </tr>
    <tr>
      <th>26</th>
      <td>J_I</td>
      <td>50</td>
      <td>13</td>
      <td>2017-01-01T02:15:00-05</td>
    </tr>
    <tr>
      <th>27</th>
      <td>J_I</td>
      <td>52</td>
      <td>19</td>
      <td>2017-01-01T02:20:00-05</td>
    </tr>
    <tr>
      <th>28</th>
      <td>J_I</td>
      <td>56</td>
      <td>11</td>
      <td>2017-01-01T02:25:00-05</td>
    </tr>
    <tr>
      <th>29</th>
      <td>J_I</td>
      <td>52</td>
      <td>10</td>
      <td>2017-01-01T02:30:00-05</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>368339</th>
      <td>BR2_BR3</td>
      <td>354</td>
      <td>1</td>
      <td>2017-01-31T19:05:00-05</td>
    </tr>
    <tr>
      <th>368340</th>
      <td>BR2_BR3</td>
      <td>484</td>
      <td>1</td>
      <td>2017-01-31T19:10:00-05</td>
    </tr>
    <tr>
      <th>368341</th>
      <td>BR2_BR3</td>
      <td>390</td>
      <td>1</td>
      <td>2017-01-31T19:15:00-05</td>
    </tr>
    <tr>
      <th>368342</th>
      <td>BR2_BR3</td>
      <td>281</td>
      <td>2</td>
      <td>2017-01-31T19:25:00-05</td>
    </tr>
    <tr>
      <th>368343</th>
      <td>BR2_BR3</td>
      <td>300</td>
      <td>1</td>
      <td>2017-01-31T19:30:00-05</td>
    </tr>
    <tr>
      <th>368344</th>
      <td>BR2_BR3</td>
      <td>300</td>
      <td>1</td>
      <td>2017-01-31T19:35:00-05</td>
    </tr>
    <tr>
      <th>368345</th>
      <td>BR2_BR3</td>
      <td>249</td>
      <td>3</td>
      <td>2017-01-31T19:50:00-05</td>
    </tr>
    <tr>
      <th>368346</th>
      <td>BR2_BR3</td>
      <td>275</td>
      <td>1</td>
      <td>2017-01-31T20:10:00-05</td>
    </tr>
    <tr>
      <th>368347</th>
      <td>BR2_BR3</td>
      <td>274</td>
      <td>1</td>
      <td>2017-01-31T20:15:00-05</td>
    </tr>
    <tr>
      <th>368348</th>
      <td>BR2_BR3</td>
      <td>252</td>
      <td>1</td>
      <td>2017-01-31T20:20:00-05</td>
    </tr>
    <tr>
      <th>368349</th>
      <td>BR2_BR3</td>
      <td>256</td>
      <td>2</td>
      <td>2017-01-31T20:25:00-05</td>
    </tr>
    <tr>
      <th>368350</th>
      <td>BR2_BR3</td>
      <td>243</td>
      <td>4</td>
      <td>2017-01-31T20:30:00-05</td>
    </tr>
    <tr>
      <th>368351</th>
      <td>BR2_BR3</td>
      <td>183</td>
      <td>1</td>
      <td>2017-01-31T20:40:00-05</td>
    </tr>
    <tr>
      <th>368352</th>
      <td>BR2_BR3</td>
      <td>266</td>
      <td>1</td>
      <td>2017-01-31T20:45:00-05</td>
    </tr>
    <tr>
      <th>368353</th>
      <td>BR2_BR3</td>
      <td>210</td>
      <td>1</td>
      <td>2017-01-31T20:50:00-05</td>
    </tr>
    <tr>
      <th>368354</th>
      <td>BR2_BR3</td>
      <td>226</td>
      <td>1</td>
      <td>2017-01-31T21:00:00-05</td>
    </tr>
    <tr>
      <th>368355</th>
      <td>BR2_BR3</td>
      <td>153</td>
      <td>1</td>
      <td>2017-01-31T21:10:00-05</td>
    </tr>
    <tr>
      <th>368356</th>
      <td>BR2_BR3</td>
      <td>229</td>
      <td>3</td>
      <td>2017-01-31T21:25:00-05</td>
    </tr>
    <tr>
      <th>368357</th>
      <td>BR2_BR3</td>
      <td>202</td>
      <td>1</td>
      <td>2017-01-31T21:30:00-05</td>
    </tr>
    <tr>
      <th>368358</th>
      <td>BR2_BR3</td>
      <td>259</td>
      <td>3</td>
      <td>2017-01-31T21:45:00-05</td>
    </tr>
    <tr>
      <th>368359</th>
      <td>BR2_BR3</td>
      <td>240</td>
      <td>1</td>
      <td>2017-01-31T21:50:00-05</td>
    </tr>
    <tr>
      <th>368360</th>
      <td>BR2_BR3</td>
      <td>216</td>
      <td>1</td>
      <td>2017-01-31T22:10:00-05</td>
    </tr>
    <tr>
      <th>368361</th>
      <td>BR2_BR3</td>
      <td>255</td>
      <td>1</td>
      <td>2017-01-31T22:15:00-05</td>
    </tr>
    <tr>
      <th>368362</th>
      <td>BR2_BR3</td>
      <td>241</td>
      <td>1</td>
      <td>2017-01-31T22:20:00-05</td>
    </tr>
    <tr>
      <th>368363</th>
      <td>BR2_BR3</td>
      <td>249</td>
      <td>4</td>
      <td>2017-01-31T22:30:00-05</td>
    </tr>
    <tr>
      <th>368364</th>
      <td>BR2_BR3</td>
      <td>248</td>
      <td>2</td>
      <td>2017-01-31T22:45:00-05</td>
    </tr>
    <tr>
      <th>368365</th>
      <td>BR2_BR3</td>
      <td>236</td>
      <td>2</td>
      <td>2017-01-31T22:55:00-05</td>
    </tr>
    <tr>
      <th>368366</th>
      <td>BR2_BR3</td>
      <td>328</td>
      <td>2</td>
      <td>2017-01-31T23:05:00-05</td>
    </tr>
    <tr>
      <th>368367</th>
      <td>BR2_BR3</td>
      <td>644</td>
      <td>1</td>
      <td>2017-01-31T23:35:00-05</td>
    </tr>
    <tr>
      <th>368368</th>
      <td>BR2_BR3</td>
      <td>202</td>
      <td>1</td>
      <td>2017-01-31T23:55:00-05</td>
    </tr>
  </tbody>
</table>
<p>368369 rows Ã— 4 columns</p>
</div>




```python
bt_2017['observed_time'] = bt_2017['updated'].str.replace('T', ' ')

del bt_2017['updated']

bt_2017.to_csv('bt_2017_fixed.csv', index=False)


```

I imported the fixed csv into PostgreSQL and checked the span of the data (January 2017). So we will create an average 24hr weekday plot for a segment on Richmond, `BR2_BR3`.


```python
weekday_avg_sql = pgsql.SQL('''
SELECT updated::TIME AS "Time", AVG(timeinseconds)
FROM bluetooth.bt_2017
WHERE resultid = {resultid} and EXTRACT('isodow' FROM updated) <6
GROUP BY "Time" 
ORDER BY "Time" ''')
```


```python
richmond_jan = pandasql.read_sql(weekday_avg_sql.format(resultid=pgsql.Literal('BR2_BR3')), con)
```


```python
trace = go.Scatter(x=richmond_jan['Time'],
                   y=richmond_jan['avg'],
                   mode='lines')
layout = dict(title = "Average Weekday Travel Times",
              xaxis = dict(title="Time of Day"),
              yaxis = dict(title="Travel Time (s)"))
```


```python
iplot(dict(data=[trace], layout=layout))
```

Great! Now testing to run this in Dash I saved this notebook as a python file and then added Dash imports:
```python
import dash
from dash.dependencies import Input, Output
import dash_core_components as dcc
import dash_html_components as html

app = dash.Dash()
```

And then adding to the bottom:
```python
app.layout = html.Div(children=[dcc.Graph(id='travel-time-graph',
                                          figure=dict(data=[trace], layout=layout))])

if __name__ == '__main__':
    app.run_server(debug=True)
```

Finally running the Dash app from the command-line with `python graph_map.py` and opening up a browser... surprise! it works!

(*yes I know there's an issue with missing data at 2:30 AM, I'll deal with that after*)

## The map
Now that we've created the simple line graph, let's see if we can display the segments on a plotly map. We're going to try to read the geometry from the database. From the [plotly mapping documentation](https://plot.ly/python/reference/#scattergeo-lon) latitude and longitude have to be passed separately as:
>lon (list, numpy array, or Pandas series of numbers, strings, or datetimes.) 

This isn't really how most geographic libraries operate, instead requiring arrays of coordinates, so this approach might be a little... hacky.


```python
geometry_sql = pgsql.SQL('''SELECT resultid, ST_ASGeoJSON(geom) geojson
FROM bluetooth.routes
WHERE resultid = {resultid} ''')
```


```python
resultid = pgsql.Literal('BR2_BR3')
```


```python
richmond_df = pandasql.read_sql(geometry_sql.format(resultid=resultid), con)
```

I'll be basing myself on [this tutorial](https://plot.ly/pandas/lines-on-maps/#contour-lines-on-globe) which, honestly, is pretty hacky. 


```python
import json
```


```python
row = richmond_df.iloc[[0]]
```


```python
# row['geojson'][0]
geojson = json.loads(row.geojson)
geojson['coordinates'][0]
```




    [-79.3691483292635, 43.6533779496959]




```python
def get_lat_lon(geojson):
    lons, lats = [], []
    for coord in geojson['coordinates']:
        lons.append(coord[0])
        lats.append(coord[1])
    return lats, lons
```


```python
segments = []

for row in richmond_df.itertuples():
    geojson = json.loads(row.geojson)
    lats, lons = get_lat_lon(geojson)
    segments.append( dict(type = 'scattergeo',
                          lon = lons, lat = lats,
                          mode = 'lines',
                          line = dict(width = 2)
                         ))
```


```python
layout = dict(
        title = 'Bluetooth segments',
        showlegend = False,
        geo = dict(
            resolution=50,
            showland = True,
            showlakes = True,
            showcountries = True,
            scope = "North America",
            projection = dict(type = "mercator"),
            lonaxis = dict( range = [-79.39, -79.36]),
            lataxis = dict( range = [43.64, 43.66])
        )
    )
iplot(dict(data=segments,layout=layout))
```

```python
mapbox_token = 'pk.eyJ1IjoicmVtb3RlZ2VudHJpZnkiLCJhIjoiY2lnanJzMjJpMDA1dnYxbHo5MTZtdGZsYSJ9.gLE8d40zmDAtMSSZyd2h1Q'


data = go.Data([
    go.Scattermapbox(
        lat=lats,
        lon=lons,
        mode='lines',
        hoverinfo='text',
        showlegend=False
    )])
    
layout = go.Layout(
    title='Bluetooth Segments',
    autosize=True,
    hovermode='closest',
    mapbox=dict(
        accesstoken=mapbox_token,
        bearing=0,
        center=dict(
            lat=43.65,
            lon=-79.37
        ),
        pitch=0,
        zoom=12,
        style='light'
    )
)    

iplot(dict(data=data,layout=layout))
```

**It works!!**

## Next Steps

I still have to test out the Mapbox map in Dash.
And then the final step is to test linking the two together using [Dash's callbacks](https://plot.ly/dash/getting-started-part-2) and then throw more data and more interactivity options. 